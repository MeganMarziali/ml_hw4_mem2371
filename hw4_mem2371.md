Assignment 4
================
Megan Marziali
Feb 3, 2021

## Part 1: Implementing a Simple Prediction Pipeline

### Loading required paackages

The following code chunk loads the required packages for the assignment.

``` r
library(tidyverse)
library(Amelia)
library(caret)
```

### Loading data into environment and cleaning

``` r
nyc_data = 
  read.csv("./data/class4_p1.csv", na = c("", ".", "NA")) %>% 
  janitor::clean_names() %>%
  mutate(
    bmi = as.numeric(bmi),
    gpaq8totmin = as.numeric(gpaq8totmin),
    gpaq11days = as.integer(gpaq11days),
    healthydays = as.integer(healthydays)
  )

summary(nyc_data)
```

    ##        x             chronic1       chronic3        chronic4    
    ##  Min.   :   1.0   Min.   :1.00   Min.   :1.000   Min.   :1.000  
    ##  1st Qu.: 953.5   1st Qu.:1.00   1st Qu.:2.000   1st Qu.:2.000  
    ##  Median :1906.0   Median :2.00   Median :2.000   Median :2.000  
    ##  Mean   :1906.0   Mean   :1.71   Mean   :1.888   Mean   :1.938  
    ##  3rd Qu.:2858.5   3rd Qu.:2.00   3rd Qu.:2.000   3rd Qu.:2.000  
    ##  Max.   :3811.0   Max.   :2.00   Max.   :2.000   Max.   :2.000  
    ##                   NA's   :28     NA's   :17      NA's   :8      
    ##       bmi           tobacco1        alcohol1      gpaq8totmin    
    ##  Min.   : 9.09   Min.   :1.000   Min.   :1.000   Min.   :  0.00  
    ##  1st Qu.:23.05   1st Qu.:3.000   1st Qu.:2.000   1st Qu.:  0.00  
    ##  Median :26.47   Median :3.000   Median :3.000   Median :  0.00  
    ##  Mean   :27.32   Mean   :2.736   Mean   :2.642   Mean   : 43.77  
    ##  3rd Qu.:30.23   3rd Qu.:3.000   3rd Qu.:3.000   3rd Qu.: 60.00  
    ##  Max.   :99.83   Max.   :3.000   Max.   :3.000   Max.   :960.00  
    ##  NA's   :73      NA's   :3       NA's   :17      NA's   :5       
    ##    gpaq11days       habits5         habits7         agegroup    
    ##  Min.   :0.000   Min.   :1.000   Min.   :1.000   Min.   :1.000  
    ##  1st Qu.:2.000   1st Qu.:1.000   1st Qu.:2.000   1st Qu.:2.000  
    ##  Median :5.000   Median :2.000   Median :3.000   Median :3.000  
    ##  Mean   :4.273   Mean   :1.972   Mean   :2.734   Mean   :2.781  
    ##  3rd Qu.:7.000   3rd Qu.:2.000   3rd Qu.:3.000   3rd Qu.:3.000  
    ##  Max.   :7.000   Max.   :4.000   Max.   :5.000   Max.   :4.000  
    ##  NA's   :5       NA's   :17      NA's   :1335    NA's   :8      
    ##       dem3            dem4            dem8        povertygroup  healthydays   
    ##  Min.   :1.000   Min.   :1.000   Min.   :1.000   Min.   :1.0   Min.   : 0.00  
    ##  1st Qu.:1.000   1st Qu.:2.000   1st Qu.:1.000   1st Qu.:2.0   1st Qu.:27.00  
    ##  Median :2.000   Median :2.000   Median :1.000   Median :3.0   Median :30.00  
    ##  Mean   :1.594   Mean   :1.777   Mean   :1.386   Mean   :3.3   Mean   :26.34  
    ##  3rd Qu.:2.000   3rd Qu.:2.000   3rd Qu.:2.000   3rd Qu.:5.0   3rd Qu.:30.00  
    ##  Max.   :2.000   Max.   :2.000   Max.   :2.000   Max.   :6.0   Max.   :30.00  
    ##                  NA's   :30      NA's   :6       NA's   :244   NA's   :88

``` r
nrow(nyc_data)
```

    ## [1] 3811

``` r
missmap(nyc_data, main = "Missing values vs observed")
```

![](hw4_mem2371_files/figure-gfm/data_prepare-1.png)<!-- -->

Based on missingness, I would not include the variables “habits7” and
“povertygroup” in any models. I would also remove all missingness from
variables that I intend to keep in models. With all variables and
missing observations included, the total N for the dataset is 3811.

``` r
nyc_restr = 
  select(nyc_data, -habits7, -povertygroup) %>% 
  na.omit()

nrow(nyc_restr)
```

    ## [1] 3552

After removing the variables “habits7” and “povertygroup”, and deleting
missing observations, the total N for the dataset is 3552.

### Data partitioning

``` r
set.seed(100)

train.indices = createDataPartition(y = nyc_restr$healthydays,p = 0.7,list = FALSE)

training = nyc_restr[train.indices,]
testing = nyc_restr[-train.indices,]
```

## Problem 1:

Fit two prediction models using different subsets of the features in the
training data. Features can overlap in the two models, but the feature
sets should not be exactly the same across models. Clearly state which
features were used in the two models.

``` r
model_1 <- lm(healthydays ~ chronic1 + chronic3 + chronic4 + bmi + gpaq8totmin + gpaq11days + habits5 + dem3, data = training)
summary(model_1)
```

    ## 
    ## Call:
    ## lm(formula = healthydays ~ chronic1 + chronic3 + chronic4 + bmi + 
    ##     gpaq8totmin + gpaq11days + habits5 + dem3, data = training)
    ## 
    ## Residuals:
    ##      Min       1Q   Median       3Q      Max 
    ## -29.6331   0.3866   2.0994   3.5958  11.3321 
    ## 
    ## Coefficients:
    ##              Estimate Std. Error t value Pr(>|t|)    
    ## (Intercept) 16.597303   2.023526   8.202 3.75e-16 ***
    ## chronic1     2.169564   0.359629   6.033 1.85e-09 ***
    ## chronic3     2.214862   0.519365   4.265 2.08e-05 ***
    ## chronic4     2.988871   0.649312   4.603 4.37e-06 ***
    ## bmi         -0.050116   0.025593  -1.958  0.05032 .  
    ## gpaq8totmin  0.001162   0.001697   0.685  0.49339    
    ## gpaq11days   0.150963   0.058346   2.587  0.00973 ** 
    ## habits5     -1.295627   0.193862  -6.683 2.88e-11 ***
    ## dem3        -0.451693   0.307560  -1.469  0.14206    
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## Residual standard error: 7.481 on 2478 degrees of freedom
    ## Multiple R-squared:  0.08678,    Adjusted R-squared:  0.08383 
    ## F-statistic: 29.44 on 8 and 2478 DF,  p-value: < 2.2e-16

``` r
model_2 <- lm(healthydays ~ tobacco1 + alcohol1 + bmi + gpaq8totmin + gpaq11days + habits5 + dem3, data = training)
summary(model_2)
```

    ## 
    ## Call:
    ## lm(formula = healthydays ~ tobacco1 + alcohol1 + bmi + gpaq8totmin + 
    ##     gpaq11days + habits5 + dem3, data = training)
    ## 
    ## Residuals:
    ##      Min       1Q   Median       3Q      Max 
    ## -29.7803   0.3876   2.3832   3.8323  10.3809 
    ## 
    ## Coefficients:
    ##               Estimate Std. Error t value Pr(>|t|)    
    ## (Intercept) 32.9718396  1.2995072  25.373  < 2e-16 ***
    ## tobacco1     0.4614780  0.2397705   1.925  0.05439 .  
    ## alcohol1    -0.8509997  0.2904958  -2.929  0.00343 ** 
    ## bmi         -0.1078506  0.0252491  -4.271 2.02e-05 ***
    ## gpaq8totmin  0.0005348  0.0017175   0.311  0.75551    
    ## gpaq11days   0.1913265  0.0591128   3.237  0.00123 ** 
    ## habits5     -1.4746880  0.1962857  -7.513 8.02e-14 ***
    ## dem3        -0.3819569  0.3168549  -1.205  0.22814    
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## Residual standard error: 7.607 on 2479 degrees of freedom
    ## Multiple R-squared:  0.05533,    Adjusted R-squared:  0.05266 
    ## F-statistic: 20.74 on 7 and 2479 DF,  p-value: < 2.2e-16

## Problem 2:

Apply both models within the test data and determine which model is the
preferred prediction model using the appropriate evaluation metric(s).

``` r
model_1_test = lm(healthydays ~ chronic1 + chronic3 + chronic4 + bmi + gpaq8totmin + gpaq11days + habits5 + dem3, data = testing)
summary(model_1_test)
```

    ## 
    ## Call:
    ## lm(formula = healthydays ~ chronic1 + chronic3 + chronic4 + bmi + 
    ##     gpaq8totmin + gpaq11days + habits5 + dem3, data = testing)
    ## 
    ## Residuals:
    ##      Min       1Q   Median       3Q      Max 
    ## -29.6935  -0.0643   1.7542   3.6952  15.1966 
    ## 
    ## Coefficients:
    ##              Estimate Std. Error t value Pr(>|t|)    
    ## (Intercept) 11.644497   2.740911   4.248 2.34e-05 ***
    ## chronic1     3.121997   0.536649   5.818 7.91e-09 ***
    ## chronic3     1.450166   0.762928   1.901   0.0576 .  
    ## chronic4     5.754809   0.922236   6.240 6.32e-10 ***
    ## bmi         -0.013702   0.036236  -0.378   0.7054    
    ## gpaq8totmin -0.001388   0.002487  -0.558   0.5770    
    ## gpaq11days   0.106914   0.087204   1.226   0.2205    
    ## habits5     -1.762960   0.281285  -6.268 5.34e-10 ***
    ## dem3        -0.714068   0.458952  -1.556   0.1200    
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## Residual standard error: 7.352 on 1056 degrees of freedom
    ## Multiple R-squared:  0.1495, Adjusted R-squared:  0.143 
    ## F-statistic:  23.2 on 8 and 1056 DF,  p-value: < 2.2e-16

``` r
model_2_test = lm(healthydays ~ tobacco1 + alcohol1 + bmi + gpaq8totmin + gpaq11days + habits5 + dem3, data = testing)
summary(model_2_test)
```

    ## 
    ## Call:
    ## lm(formula = healthydays ~ tobacco1 + alcohol1 + bmi + gpaq8totmin + 
    ##     gpaq11days + habits5 + dem3, data = testing)
    ## 
    ## Residuals:
    ##      Min       1Q   Median       3Q      Max 
    ## -29.6143   0.1812   2.1979   3.9066  12.0326 
    ## 
    ## Coefficients:
    ##              Estimate Std. Error t value Pr(>|t|)    
    ## (Intercept) 34.251675   1.957066  17.502  < 2e-16 ***
    ## tobacco1     0.684645   0.378467   1.809  0.07074 .  
    ## alcohol1    -1.262148   0.446293  -2.828  0.00477 ** 
    ## bmi         -0.075462   0.036974  -2.041  0.04151 *  
    ## gpaq8totmin -0.001572   0.002581  -0.609  0.54261    
    ## gpaq11days   0.138536   0.090553   1.530  0.12634    
    ## habits5     -2.075579   0.289589  -7.167 1.43e-12 ***
    ## dem3        -0.580140   0.489222  -1.186  0.23595    
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## Residual standard error: 7.639 on 1057 degrees of freedom
    ## Multiple R-squared:  0.08094,    Adjusted R-squared:  0.07485 
    ## F-statistic:  13.3 on 7 and 1057 DF,  p-value: < 2.2e-16

``` r
mse_1 = sum(model_1_test$residuals^2)
mse_2 = sum(model_2_test$residuals^2)
```

The outcome we are investigating is continuous, so the appropriate
evaluation metric is to assess mean squared error. As model 1 has the
smaller mean squared error, we can determine that model 1 is the
preferred prediction model.

## Problem 3

The implementation of this model would be helpful if in cases where we
are trying to identify factors to intervene on to increase the number of
healthy days experienced. As the model works to identify predictors of a
higher number of healthy days, we know that those predictors function to
increase healthy days experienced.
