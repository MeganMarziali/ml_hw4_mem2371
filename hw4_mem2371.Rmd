---
title: "Assignment 4"
author: "Megan Marziali"
date: "Feb 3, 2021"
output:
  github_document: default
editor_options:
  chunk_output_type: console
---

## Part 1: Implementing a Simple Prediction Pipeline

### Problem set-up

##### Loading required paackages

The following code chunk loads the required packages for the assignment.
```{r packages, message = FALSE}
library(tidyverse)
library(Amelia)
library(caret)
library(stats)
library(factoextra)
library(cluster)

set.seed(100)
```

##### Loading data into environment and cleaning

```{r data_prepare, message = FALSE}
nyc_data = 
  read.csv("./data/class4_p1.csv", na = c("", ".", "NA", ".d", ".r")) %>% 
  janitor::clean_names() %>%
  mutate(
    bmi = as.numeric(bmi),
    gpaq8totmin = as.numeric(gpaq8totmin),
    gpaq11days = as.integer(gpaq11days),
    healthydays = as.integer(healthydays),
    chronic1 = as.factor(chronic1),
    chronic3 = as.factor(chronic3),
    chronic4 = as.factor(chronic4),
    tobacco1 = as.factor(tobacco1),
    alcohol1 = as.factor(alcohol1),
    agegroup = as.factor(agegroup),
    dem3 = as.factor(dem3),
    dem4 = as.factor(dem4),
    dem8 = as.factor(dem8),
    povertygroup = as.factor(povertygroup)
  ) 

summary(nyc_data)
nrow(nyc_data)

missmap(nyc_data, main = "Missing values vs observed")
```

To clean the data, I recoded variables to be factor or numerical variables. To further explore the data, I mapped the number of missing observations. Based on missingness, I would not include the variables "habits7" and "povertygroup" in any models. I would also remove all missingness from variables that I intend to keep in models. With all variables and missing observations included, the total N for the dataset is 3811.

```{r, message = FALSE}
nyc_restr = 
  select(nyc_data, -habits7, -povertygroup) %>% 
  na.omit() %>% 
  distinct(x, .keep_all = TRUE)

nrow(nyc_restr)
```

The variable "habits7" has 1335 missing observations (35.0%) and the variable "povertygroup" has 244 missing observations (6.4%). As both have >5% missing values, I opted to drop them both from the dataset.After removing the variables "habits7" and "povertygroup", and deleting missing observations from all other included variables, the total N for the dataset is 3552.

##### Data partitioning

```{r partition, message = FALSE}
train.indices = createDataPartition(y = nyc_restr$healthydays,p = 0.7,list = FALSE)

training = nyc_restr[train.indices,]
testing = nyc_restr[-train.indices,]
```

### Problem 1:

Fit two prediction  models using  different subsets of the features in the training data. Features can overlap in the two models, but the feature sets should not be exactly the same across models. Clearly state which features were used in the two models.

```{r models, message = FALSE}
model_1 <- lm(healthydays ~ chronic1 + chronic3 + chronic4 + bmi + gpaq8totmin + gpaq11days + habits5 + dem3, data = training)
summary(model_1)

model_2 <- lm(healthydays ~ tobacco1 + alcohol1 + bmi + gpaq8totmin + gpaq11days + habits5 + dem3, data = training)
summary(model_2)
```

### Problem 2:

Apply both models within the test data and determine which model is the preferred prediction model using the appropriate evaluation metric(s). 

```{r predictvalues, message = FALSE}
fitted_1 = predict(model_1,testing,type = 'response') 
fitted_2 = predict(model_2,testing,type = 'response') 
observed = testing$healthydays

mse_1 = mean((observed - fitted_1)**2)
mse_2 = mean((observed - fitted_2)**2)
```

The outcome we are investigating is continuous, so the appropriate evaluation metric is to assess mean squared error. As model 1 has the smaller mean squared error, we can determine that model 1 is the preferred prediction model.

### Problem 3

The implementation of this model would be helpful for preventative care. We could use predictive modeling to identify factors to intervene on, in order to increase the number of healthy days experienced. As the model works to identify predictors of a higher number of healthy days, we know that those predictors function to increase healthy days experienced.

## Part II

#### Problem set-up

```{r dataprep2}
data("USArrests")
head(USArrests)

#Removing missing
us_arrest = na.omit(USArrests)

colMeans(us_arrest, na.rm = TRUE)
apply(us_arrest, 2, sd, na.rm = TRUE)

scale(us_arrest, center = TRUE, scale = TRUE)
```

The code chunk above calls the appropriate dataset, removes any potential missing observations, checks if scaling is necessary and scales the data.

### Problem 4

```{r}
# Create Dissimilarity matrix
diss.matrix = dist(us_arrest, method = "euclidean")
```

#### Part 1: Complete Linkage

```{r}
clusters_c = hclust(diss.matrix, method = "complete" )

plot(clusters_c, cex = 0.6, hang = -1)

hclusCut = function(x, k) list(cluster = cutree(hclust(dist(x, method = "euclidian"), method = "complete"), k = k))

gap_stat = clusGap(us_arrest, FUN = hclusCut, K.max = 10, B = 50)
fviz_gap_stat(gap_stat)

#Use number of clusters from gap statistic to obtain cluster assignment for each observation
clusters_c_3 = cutree(clusters_c, k = 3)
table(clusters_c_3)
```

After running the above hierarchical clustering model using the "complete" linkage method, the optimal number of clusters per the gap statistic is 3.

Within cluster 1, there are 16 states included; cluster 2 includes 14 states, and cluster 3 includes 20 states.

#### Part 2: Average Linkage

```{r}
clusters_a = hclust(diss.matrix, method = "average" )

plot(clusters_a, cex = 0.6, hang = -1)

hclusCut = function(x, k) list(cluster = cutree(hclust(dist(x, method = "euclidian"), method = "average"), k = k))

gap_stat = clusGap(us_arrest, FUN = hclusCut, K.max = 10, B = 50)
fviz_gap_stat(gap_stat)

#Investigating cluster composition
clusters_a_3 = cutree(clusters_a, k = 3)
table(clusters_a_3)
```

After running the above hierarchical clustering model using the "average" linkage method, the optimal number of clusters per the gap statistic is 3.

Within cluster 1, there are 16 states included; cluster 2 includes 14 states, and cluster 3 includes 20 states. Given these results, there are no differences between using the complete or average linkage method, as both point towards using 3 clusters.

### Problem 5

Using the clusters as exposures, we could assess whether different arrest rates are resulting in poor health outcomes.